{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctoralia Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [How many facilities do we have?](#1-how-many-facilities-do-we-have)\n",
    "2. [How many premium facilities do we have?](#2-how-many-premium-facilities-do-we-have)\n",
    "3. [What’s the facilities distribution by size?](#3-whats-the-facilities-distribution-by-size)\n",
    "4. [How many valid phones do we have?](#4-how-many-valid-phones-do-we-have)\n",
    "5. [What’s the state with the most premium facilities as of today?](#5-whats-the-state-with-the-most-premium-facilities-as-of-today)\n",
    "6. [How many facilities have churned since June 2022?](#6-how-many-facilities-have-churned-since-june-2022)\n",
    "7. [What’s the top 3 states with the highest churn percentage?](#7-whats-the-top-3-states-with-the-highest-churn-percentage)\n",
    "8. [What’s the churn probability for facilities in its 5th month (at national level)?](#8-whats-the-churn-probability-for-facilities-in-its-5th-month-at-national-level)\n",
    "9. [What’s the top 3 states with the most invalid phone number proportion?](#9-whats-the-top-3-states-with-the-most-invalid-phone-number-proportion)\n",
    "10. [What’s the average facilities lifespan?](#10-whats-the-average-facilities-lifespan)\n",
    "11. [What’s the top 3 states with the biggest facilities?](#11-whats-the-top-3-states-with-the-biggest-facilities)\n",
    "12. [Do we have duplicated phone numbers?](#12-do-we-have-duplicated-phone-numbers)\n",
    "13. [What’s the top 3 valid duplicated numbers?](#13-whats-the-top-3-valid-duplicated-numbers)\n",
    "14. [What’s the top 3 states with the most valid duplicated numbers?](#14-whats-the-top-3-states-with-the-most-valid-duplicated-numbers)\n",
    "15. [What is the relation between valid/invalid phones with churn propensity?](#15-what-is-the-relation-between-validinvalid-phones-with-churn-propensity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_format = '%(asctime)s %(levelname)s: \\n%(message)s\\n'\n",
    "\n",
    "# Configure the logger with the custom format\n",
    "logging.basicConfig(filename=\"logs/LoggerDoctoralia.log\",\n",
    "                    level=logging.INFO,\n",
    "\t\t\t\t\tformat=log_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/CS_Ops_Assessment_dataset_JuanReyes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get rid of the trailing white spaces of the columns\n",
    "df.columns = df.columns.str.strip()\n",
    "#Let's get rid of the trailing white spaces of the all the rows\n",
    "df = df.map(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line wrapping in the display\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the unique values per column of interest\n",
    "print(f\"\"\"\n",
    "Unique Facility Categories:\n",
    "{df['facility_category'].unique()}\n",
    "\n",
    "Unique Facility Sizes:\n",
    "{df['facility_size'].unique()}\n",
    "\n",
    "Unique States:\n",
    "{df['state'].unique()}\n",
    "\n",
    "Unique Cities:\n",
    "{df['city'].unique()}\n",
    "\n",
    "Unique Is_premium:\n",
    "{df[\"is_premium\"].unique()}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Analysis (IDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace standalone word 'na' not words that contain 'nan'\n",
    "df = df.replace(r'\\bna\\b', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN for NaT & ensuring dates are in datetime64\n",
    "def parse_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%m/%d/%Y\")\n",
    "    except ValueError:\n",
    "        print(f\"Failed to parse '{date_str}'\")\n",
    "        pass\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "df['churn_since'] = df['churn_since'].apply(parse_date)\n",
    "df['premium_since'] = df['premium_since'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_churn'] = df['is_churn'].astype('Int64') #We do this to handle NaNs & to ensure nums are int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_premium'] = df['is_premium'].astype(int)  # Ensure it is an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phone'] = df['phone'].astype(int) #If we leave it as float there are mistakes\n",
    "df['phone'] = df['phone'].astype(str) #We need this to determine valid numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How many facilities do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming facility_id is a primary key then the number of facilities is simply the total number of unique entries\n",
    "total_facilities = df[\"facility_id\"].nunique()\n",
    "\n",
    "print(total_facilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How many premium facilities do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two approaches\n",
    "total_premium_facilities = df['is_premium'].value_counts().get(1, 0)\n",
    "total_premium_facilities_query = df.query('is_premium == 1').shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_premium_facilities)\n",
    "print(total_premium_facilities_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What’s the facilities distribution by size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking a groupby operation\n",
    "facility_size_distribution = df['facility_size'].value_counts()\n",
    "print(facility_size_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How many valid phones do we have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#All valid numbers in MX need to have 10 digits: https://telmex.com/10digitos\n",
    "\n",
    "df_ten_digits_phones = df.loc[df['phone'].str.len() == 10].copy()\n",
    "\n",
    "\n",
    "#Surprisingly hard to find a reliable source for a complete list of LADA. Got it from https://www.bajaregroup.com/pdf/mexican_area_codes.pdf\n",
    "\n",
    "with open('data/TodasLadaMexico.md', 'r', encoding='utf-8') as file:\n",
    "    md_content = file.read()\n",
    "\n",
    "lines = md_content.strip().split('\\n')\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    # Split on the last occurrence of '. '\n",
    "    parts = line.rsplit('. ', 1)\n",
    "    if len(parts) == 2:\n",
    "        city_with_state, lada = parts\n",
    "        data.append({'city_with_state': city_with_state, 'lada': lada})\n",
    "\n",
    "df_lada = pd.DataFrame(data)\n",
    "\n",
    "df_lada['lada'] = df_lada['lada'].astype(str)\n",
    "\n",
    "lada_numbers = set(df_lada['lada'])\n",
    "\n",
    "def check_lada_vectorized(phone_numbers):\n",
    "    mask_two_digits = phone_numbers.str[:2].isin(lada_numbers)\n",
    "    mask_three_digits = phone_numbers.str[:3].isin(lada_numbers)\n",
    "    return mask_two_digits | mask_three_digits\n",
    "\n",
    "df_ten_digits_phones.loc[:, 'lada_check'] = check_lada_vectorized(df_ten_digits_phones['phone'])\n",
    "\n",
    "invalid_lada_phones = df_ten_digits_phones.loc[~df_ten_digits_phones['lada_check'], 'phone']\n",
    "for phone in invalid_lada_phones:\n",
    "    logging.error(f\"Phone number does not match LADA pattern: {phone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of phone numbers with exactly 10 digits & valid LADA codes: 296\n"
     ]
    }
   ],
   "source": [
    "valid_phones_df = df_ten_digits_phones.loc[df_ten_digits_phones['lada_check'] == True]\n",
    "number_of_valid_phones = valid_phones_df.shape[0]\n",
    "\n",
    "print(f\"Number of phone numbers with exactly 10 digits & valid LADA codes: {number_of_valid_phones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What’s the state with the most premium facilities as of today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premium_counts_by_state = df[df['is_premium'] == 1]['state'].value_counts()\n",
    "print(f\"Counts of premium facilities by state:{premium_counts_by_state}\")\n",
    "\n",
    "most_premium_state = premium_counts_by_state.idxmax()\n",
    "print(f\"\\nThe state with the most premium facilities is: {most_premium_state} with {premium_counts_by_state.max()} premium facilities.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How many facilities have churned since June 2022?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_since_june_df = df[(df['is_churn'] == 1) & (df['churn_since'] > pd.to_datetime('2022-06-01'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_since_june_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_since_june_df[\"facility_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. What’s the top 3 states with the highest churn percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "churn_percentage_by_state = df.groupby('state')['is_churn'].mean() * 100\n",
    "sorted_states = churn_percentage_by_state.sort_values(ascending=False)\n",
    "top_3_states = sorted_states.head(3)\n",
    "\n",
    "print(sorted_states, \"\\n\\n\", top_3_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campeche = df.query('state == \"campeche\"')\n",
    "campeche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. What’s the churn probability for facilities in its 5th month (at national level)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_date = datetime.now()\n",
    "\n",
    "df['tenure_days'] = np.where(\n",
    "    pd.notnull(df['churn_since']),\n",
    "    (df['churn_since'] - df['premium_since']).dt.days,\n",
    "    (reference_date - df['premium_since']).dt.days\n",
    ")\n",
    "\n",
    "# Fill NaN values that result from NaT entries with the placeholder -1\n",
    "df['tenure_days'] = df['tenure_days'].fillna(-1)\n",
    "\n",
    "df['tenure_months'] = (df['tenure_days'] / 30.44).astype(int)\n",
    "\n",
    "\n",
    "#Starts on 0 so 5th month is 4. Also, this includes facilities that churned exactly on the 5th month mark\n",
    "facilities_in_5th_month = df[(df['tenure_months'] == 4)]\n",
    "facilities_in_5th_month.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churned_in_5th_month = facilities_in_5th_month[facilities_in_5th_month['is_churn'] == 1].shape[0]\n",
    "total_premium_facilities = df[pd.notnull(df['premium_since'])].shape[0]\n",
    "\n",
    "churn_probability_5th_month = churned_in_5th_month / total_premium_facilities\n",
    "\n",
    "print(f\"The churn probability for a facility in its 5th month is: {churn_probability_5th_month:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. What’s the top 3 states with the most invalid phone number proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invalid_phone'] = 0\n",
    "\n",
    "df.loc[df['phone'].str.len() != 10, 'invalid_phone'] = 1\n",
    "\n",
    "state_phone_stats = df.groupby('state')['invalid_phone'].agg(['sum', 'count'])\n",
    "\n",
    "state_phone_stats[\"invalid_phone_proportion\"] = state_phone_stats[\"sum\"] / state_phone_stats[\"count\"]\n",
    "\n",
    "top_invalid_phone_states = state_phone_stats.sort_values(by='invalid_phone_proportion', ascending=False)\n",
    "\n",
    "top_invalid_phone_states.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. What’s the average facilities lifespan?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lifespan = df[\"tenure_days\"].mean()\n",
    "\n",
    "print(f\"The average facilities lifespan is {avg_lifespan:.0f} days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. What’s the top 3 states with the biggest facilities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_facility_categories = ['51 a 100 personas', '101 a 250 personas', '251 y mas personas']\n",
    "big_facilities_df = df[df['facility_size'].isin(big_facility_categories)]\n",
    "state_category_crosstab = pd.crosstab(big_facilities_df['state'], big_facilities_df['facility_size'])\n",
    "\n",
    "state_category_crosstab['Total'] = state_category_crosstab.sum(axis=1)\n",
    "\n",
    "print(state_category_crosstab.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Do we have duplicated phone numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones_not_0 = df[df['phone'] != '0']\n",
    "\n",
    "#We are NOT keeping the first occurence.\n",
    "duplicated_phones = phones_not_0['phone'].duplicated(keep=False)\n",
    "\n",
    "number_of_duplicated_phones = duplicated_phones.sum()\n",
    "\n",
    "df_duplicated_phones = phones_not_0[duplicated_phones]\n",
    "\n",
    "print(f\"There are {number_of_duplicated_phones} duplicated phone numbers, excluding the placeholder '0'.\\n{df_duplicated_phones['phone']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. What’s the top 3 valid duplicated numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_duplicated_phones = df_duplicated_phones.loc[df_duplicated_phones['invalid_phone'] == 0]\n",
    "\n",
    "top_valid_duplicated_phones = df_valid_duplicated_phones[\"phone\"].value_counts()\n",
    "\n",
    "top_valid_duplicated_phones.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. What’s the top 3 states with the most valid duplicated numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "valid_duplicated_phones_crosstab = pd.crosstab(df_valid_duplicated_phones['state'], df_valid_duplicated_phones['phone'])\n",
    "\n",
    "valid_duplicated_phones_crosstab['Total'] = valid_duplicated_phones_crosstab.sum(axis=1)\n",
    "\n",
    "valid_duplicated_phones_crosstab.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. What is the relation between valid/invalid phones with churn propensity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df_chi.drop_duplicates(subset='phone', keep='first', inplace=True)\n",
    "df_no_zeros = df[df['phone'] != 0]\n",
    "df_no_zeros_dropped = df_no_zeros.drop_duplicates()\n",
    "df_zeros = df[df['phone'] == 0]\n",
    "df_chi = pd.concat([df_no_zeros_dropped, df_zeros], ignore_index=True)\n",
    "\n",
    "df_chi = df_chi.sort_values(by='facility_id')\n",
    "\n",
    "df_chi = df.dropna(subset=['is_churn'])\n",
    "\n",
    "print(df_chi.info(), \"\\n\\n\\n\")\n",
    "\n",
    "invalid_phone_counts = df_chi['invalid_phone'].value_counts()\n",
    "is_churn_counts = df_chi['is_churn'].value_counts()\n",
    "\n",
    "\n",
    "print(f\"invalid_phone_counts: {invalid_phone_counts}\\n\")\n",
    "print(f\"is_churn_counts: {is_churn_counts}\\n\")\n",
    "\n",
    "contingency_table = pd.crosstab(df_chi['invalid_phone'], df_chi['is_churn'])\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-squared test results:\\n\")\n",
    "print(f\"Chi-squared: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "alpha = 0.05  \n",
    "if p < alpha:\n",
    "    print(\"There is a significant relationship between phone validity and churn propensity.\")\n",
    "else:\n",
    "    print(\"There is no significant relationship between phone validity and churn propensity.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit = df.copy()\n",
    "\n",
    "#df_logit = df_logit[df_logit['phone'] != '0']\n",
    "\n",
    "#Drop the duplicates\n",
    "df_logit.drop_duplicates(subset='phone', keep='first', inplace=True)\n",
    "\n",
    "X = df_logit[['invalid_phone']]  \n",
    "y = df_logit['is_churn'].dropna()\n",
    "\n",
    "# Since 'is_churn' has missing values, we need to filter those out\n",
    "X = X.loc[y.index]\n",
    "\n",
    "X_counts = X.value_counts()\n",
    "\n",
    "y_counts = y.value_counts()\n",
    "\n",
    "print(f\"X_counts: {X_counts}\\n\\ny_counts: {y_counts}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"Coefficient for invalid_phone: {model.coef_[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

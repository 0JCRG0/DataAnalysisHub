{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doctoralia Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [How many facilities do we have?](#1-how-many-facilities-do-we-have)\n",
    "2. [How many premium facilities do we have?](#2-how-many-premium-facilities-do-we-have)\n",
    "3. [What’s the facilities distribution by size?](#3-whats-the-facilities-distribution-by-size)\n",
    "4. [How many valid phones do we have?](#4-how-many-valid-phones-do-we-have)\n",
    "5. [What’s the state with the most premium facilities as of today?](#5-whats-the-state-with-the-most-premium-facilities-as-of-today)\n",
    "6. [How many facilities have churned since June 2022?](#6-how-many-facilities-have-churned-since-june-2022)\n",
    "7. [What’s the top 3 states with the highest churn percentage?](#7-whats-the-top-3-states-with-the-highest-churn-percentage)\n",
    "8. [What’s the churn probability for facilities in its 5th month (at national level)?](#8-whats-the-churn-probability-for-facilities-in-its-5th-month-at-national-level)\n",
    "9. [What’s the top 3 states with the most invalid phone number proportion?](#9-whats-the-top-3-states-with-the-most-invalid-phone-number-proportion)\n",
    "10. [What’s the average facilities lifespan?](#10-whats-the-average-facilities-lifespan)\n",
    "11. [What’s the top 3 states with the biggest facilities?](#11-whats-the-top-3-states-with-the-biggest-facilities)\n",
    "12. [Do we have duplicated phone numbers?](#12-do-we-have-duplicated-phone-numbers)\n",
    "13. [What’s the top 3 valid duplicated numbers?](#13-whats-the-top-3-valid-duplicated-numbers)\n",
    "14. [What’s the top 3 states with the most valid duplicated numbers?](#14-whats-the-top-3-states-with-the-most-valid-duplicated-numbers)\n",
    "15. [What is the relation between valid/invalid phones with churn propensity?](#15-what-is-the-relation-between-validinvalid-phones-with-churn-propensity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_format = '%(asctime)s %(levelname)s: \\n%(message)s\\n'\n",
    "\n",
    "logging.basicConfig(filename=\"logs/LoggerDoctoralia.log\",\n",
    "                    level=logging.INFO,\n",
    "\t\t\t\t\tformat=log_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/CS_Ops_Assessment_dataset_JuanReyes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get rid of the trailing white spaces of the columns\n",
    "df.columns = df.columns.str.strip()\n",
    "#Let's get rid of the trailing white spaces of the all the rows\n",
    "df = df.map(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line wrapping in the display\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the unique values per column of interest\n",
    "print(f\"\"\"\n",
    "Unique Facility Categories:\n",
    "{df['facility_category'].unique()}\n",
    "\n",
    "Unique Facility Sizes:\n",
    "{df['facility_size'].unique()}\n",
    "\n",
    "Unique States:\n",
    "{df['state'].unique()}\n",
    "\n",
    "Unique Cities:\n",
    "{df['city'].unique()}\n",
    "\n",
    "Unique Is_premium:\n",
    "{df[\"is_premium\"].unique()}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Analysis (IDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace standalone word 'na', not words that contain 'nan'\n",
    "df = df.replace(r'\\bna\\b', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN for NaT & ensuring dates are in datetime64\n",
    "def parse_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%m/%d/%Y\")\n",
    "    except ValueError:\n",
    "        logging.error(f\"Failed to parse '{date_str}'\")\n",
    "        pass\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "df['churn_since'] = df['churn_since'].apply(parse_date)\n",
    "df['premium_since'] = df['premium_since'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_churn'] = df['is_churn'].astype('Int64') #We do this to handle NaNs & to ensure nums are int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_premium'] = df['is_premium'].astype(int)  # Ensure it is an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phone'] = df['phone'].astype(int) #If we leave it as float there are mistakes\n",
    "df['phone'] = df['phone'].astype(str) #We need this to determine valid phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How many facilities do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_facilities = df[\"facility_id\"].nunique()\n",
    "\n",
    "print(f\"Doctoralia has a total of {total_facilities} facilities\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How many premium facilities do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two approaches\n",
    "total_premium_facilities_df = df[(df[\"is_premium\"] == 1)]\n",
    "total_premium_facilities_active_df = df[(df[\"is_premium\"] == 1) & (df[\"is_churn\"] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Historically, Doctoralia has had a total of {total_premium_facilities_df.shape[0]} premium facilities\")\n",
    "print(f\"As of today, Doctoralia has a total of {total_premium_facilities_active_df.shape[0]} active premium facilities\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What’s the facilities distribution by size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking a groupby operation\n",
    "facility_size_distribution = df['facility_size'].value_counts()\n",
    "print(facility_size_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How many valid phones do we have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Surprisingly hard to find a reliable source for a complete list of LADA codes. Got it from https://www.bajaregroup.com/pdf/mexican_area_codes.pdf\n",
    "\n",
    "with open('data/TodasLadaMexico.md', 'r', encoding='utf-8') as file:\n",
    "    md_content = file.read()\n",
    "\n",
    "lines = md_content.strip().split('\\n')\n",
    "\n",
    "data = []\n",
    "for line in lines:\n",
    "    # Split on the last occurrence of '. '\n",
    "    parts = line.rsplit('. ', 1)\n",
    "    if len(parts) == 2:\n",
    "        city_with_state, lada = parts\n",
    "        data.append({'city_with_state': city_with_state, 'lada': lada})\n",
    "\n",
    "df_lada = pd.DataFrame(data)\n",
    "\n",
    "df_lada['lada'] = df_lada['lada'].astype(str)\n",
    "\n",
    "lada_numbers = set(df_lada['lada'])\n",
    "\n",
    "def check_lada_vectorized(phone_numbers):\n",
    "    mask_two_digits = phone_numbers.str[:2].isin(lada_numbers)\n",
    "    mask_three_digits = phone_numbers.str[:3].isin(lada_numbers)\n",
    "    return mask_two_digits | mask_three_digits\n",
    "\n",
    "df.loc[:, 'lada_check'] = check_lada_vectorized(df['phone'])\n",
    "\n",
    "#All valid numbers in MX need to have 10 digits: https://telmex.com/10digitos\n",
    "\n",
    "mask_ten_digits = df['phone'].str.len() == 10\n",
    "\n",
    "df['lada_check'] = np.where(mask_ten_digits, df['lada_check'], pd.NA)\n",
    "\n",
    "# Log phone numbers that do not match the LADA pattern\n",
    "invalid_lada_phones = df.loc[df['lada_check'] == False, 'phone']\n",
    "for phone in invalid_lada_phones:\n",
    "    logging.error(f\"Phone number does not match LADA pattern: {phone}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_phones_df = df.loc[df['lada_check'] == True]\n",
    "number_of_valid_phones = valid_phones_df.shape[0]\n",
    "\n",
    "print(f\"Number of phone numbers with exactly 10 digits & valid LADA codes: {number_of_valid_phones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What’s the state with the most premium facilities as of today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premium_counts_by_state = df[(df['is_premium'] == 1) & (df['is_churn'] == 0)]['state'].value_counts()\n",
    "print(f\"Counts of premium facilities by state with an active premium status:\\n{premium_counts_by_state}\")\n",
    "\n",
    "most_premium_state = premium_counts_by_state.idxmax()\n",
    "print(f\"\\nThe state with the most premium facilities is: {most_premium_state} with {premium_counts_by_state.max()} active premium facilities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How many facilities have churned since June 2022?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_since_june_df = df[(df['is_churn'] == 1) & (df['churn_since'] >= pd.to_datetime('2022-06-01'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_since_june_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_since_june = churn_since_june_df.shape[0]\n",
    "\n",
    "print(f\"{churn_since_june} facilities have churned since June 2022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. What’s the top 3 states with the highest churn percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "churn_percentage_by_state = df.groupby('state')['is_churn'].mean() * 100\n",
    "sorted_states = churn_percentage_by_state.sort_values(ascending=False)\n",
    "top_3_states = sorted_states.head(3)\n",
    "\n",
    "print(sorted_states, \"\\n\\n\", top_3_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#campeche = df.query('state == \"campeche\"')\n",
    "#campeche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. What’s the churn probability for facilities in its 5th month (at national level)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_date = datetime.now()\n",
    "\n",
    "df['tenure_days'] = np.where(\n",
    "    pd.notnull(df['churn_since']),\n",
    "    (df['churn_since'] - df['premium_since']).dt.days,\n",
    "    (reference_date - df['premium_since']).dt.days\n",
    ")\n",
    "\n",
    "# Fill NaN values that result from NaT entries with the placeholder -1\n",
    "df['tenure_days'] = df['tenure_days'].fillna(-1)\n",
    "\n",
    "df['tenure_months'] = (df['tenure_days'] / 30.44).astype(int)\n",
    "\n",
    "facilities_at_least_5_months_old = df[df['tenure_months'] >= 4]\n",
    "\n",
    "facilities_in_5th_month = facilities_at_least_5_months_old[facilities_at_least_5_months_old['tenure_months'] == 4]\n",
    "churned_in_5th_month = facilities_in_5th_month[facilities_in_5th_month['is_churn'] == 1].shape[0]\n",
    "total_facilities_in_5th_month = facilities_in_5th_month.shape[0]\n",
    "\n",
    "if total_facilities_in_5th_month > 0:\n",
    "    churn_probability_5th_month = churned_in_5th_month / total_facilities_in_5th_month\n",
    "    print(f\"The churn probability for a facility in its 5th month is: {churn_probability_5th_month:.2%}\")\n",
    "else:\n",
    "    print(\"There are no facilities in their 5th month to calculate churn probability.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. What’s the top 3 states with the most invalid phone number proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invalid_phone'] = 0\n",
    "\n",
    "df.loc[df['lada_check'] != True, 'invalid_phone'] = 1\n",
    "\n",
    "state_phone_stats = df.groupby('state')['invalid_phone'].agg(['sum', 'count'])\n",
    "\n",
    "state_phone_stats[\"invalid_phone_proportion\"] = state_phone_stats[\"sum\"] / state_phone_stats[\"count\"]\n",
    "\n",
    "top_invalid_phone_states = state_phone_stats.sort_values(\n",
    "    by=['invalid_phone_proportion', 'sum'], \n",
    "    ascending=[False, False]\n",
    ")\n",
    "\n",
    "top_invalid_phone_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guanajuato = df.query(\"state == 'guanajuato'\")\n",
    "guanajuato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. What’s the average facilities lifespan?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lifespan = df[\"tenure_days\"].mean()\n",
    "\n",
    "print(f\"The average facilities lifespan is {avg_lifespan:.0f} days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. What’s the top 3 states with the biggest facilities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_facility_categories = ['51 a 100 personas', '101 a 250 personas', '251 y mas personas']\n",
    "big_facilities_df = df[df['facility_size'].isin(big_facility_categories)]\n",
    "state_category_crosstab = pd.crosstab(big_facilities_df['state'], big_facilities_df['facility_size'])\n",
    "\n",
    "state_category_crosstab['Total'] = state_category_crosstab.sum(axis=1)\n",
    "\n",
    "print(state_category_crosstab.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Do we have duplicated phone numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones_not_0 = df[df['phone'] != '0']\n",
    "\n",
    "#We are NOT keeping the first occurence.\n",
    "duplicated_phones = phones_not_0['phone'].duplicated(keep=False)\n",
    "\n",
    "number_of_duplicated_phones = duplicated_phones.sum()\n",
    "\n",
    "df_duplicated_phones = phones_not_0[duplicated_phones]\n",
    "\n",
    "print(f\"There are {number_of_duplicated_phones} duplicated phone numbers, excluding the placeholder '0' and not keeping the first occurence.\\n{df_duplicated_phones['phone']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. What’s the top 3 valid duplicated numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_duplicated_phones = df_duplicated_phones.loc[df_duplicated_phones['invalid_phone'] == 0]\n",
    "\n",
    "top_valid_duplicated_phones = df_valid_duplicated_phones[\"phone\"].value_counts()\n",
    "\n",
    "top_valid_duplicated_phones.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. What’s the top 3 states with the most valid duplicated numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "valid_duplicated_phones_crosstab = pd.crosstab(df_valid_duplicated_phones['state'], df_valid_duplicated_phones['phone'])\n",
    "\n",
    "valid_duplicated_phones_crosstab['Total'] = valid_duplicated_phones_crosstab.sum(axis=1)\n",
    "\n",
    "valid_duplicated_phones_crosstab.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. What is the relation between valid/invalid phones with churn propensity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_no_zeros = df[df['phone'] != 0]\n",
    "df_no_zeros_dropped = df_no_zeros.drop_duplicates()\n",
    "df_zeros = df[df['phone'] == 0]\n",
    "df_chi = pd.concat([df_no_zeros_dropped, df_zeros], ignore_index=True)\n",
    "\n",
    "df_chi = df_chi.sort_values(by='facility_id')\n",
    "\n",
    "df_chi = df.dropna(subset=['is_churn'])\n",
    "\n",
    "invalid_phone_counts = df_chi['invalid_phone'].value_counts()\n",
    "is_churn_counts = df_chi['is_churn'].value_counts()\n",
    "\n",
    "\n",
    "print(f\"invalid_phone_counts: {invalid_phone_counts}\\n\")\n",
    "print(f\"is_churn_counts: {is_churn_counts}\\n\")\n",
    "\n",
    "contingency_table = pd.crosstab(df_chi['invalid_phone'], df_chi['is_churn'])\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-squared test results:\\n\")\n",
    "print(f\"Chi-squared: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)\n",
    "\n",
    "alpha = 0.05  \n",
    "if p < alpha:\n",
    "    print(\"There is a significant relationship between phone validity and churn propensity.\")\n",
    "else:\n",
    "    print(\"There is no significant relationship between phone validity and churn propensity.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest = df_chi.copy()\n",
    "\n",
    "df_forest = df_forest.dropna(subset=['is_churn'])\n",
    "\n",
    "categorical_cols = ['facility_category', 'facility_size', 'state']\n",
    "numerical_cols = ['tenure_months', 'invalid_phone']\n",
    "\n",
    "features = categorical_cols + numerical_cols\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_cols)], remainder='passthrough')\n",
    "\n",
    "X_transformed = ct.fit_transform(df_forest[features])\n",
    "\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "y = df_forest['is_churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])}\")\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "print(importances.sort_values('importance', ascending=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
